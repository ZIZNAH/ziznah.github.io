{"posts":[{"title":"Mikrotik 指定不同网关与DNS","content":"Mikrotik 指定不同网关与DNS RouterOS 使用 **DHCP Options **，手动指定不同设备使用不同网关与 DNS。 本地设置 我的 ROS 地址为 192.168.5.1，DHCP 服务器分配的网关为192.168.5.1，DNS 服务器为192.168.5.1 （因为我开启了 ROS 缓存功能） 默认接入的设备分配到的网关和 DNS 就是 192.168.5.1。那么如何实现随意设备走指定网关呢，就需要用到 Options 功能： Options 参数 Name： 名称，这个随意 Code： Options 编号，用数字表示。 3 表示网关， 6 表示 DNS。后面会将详细的表贴出来 Value： Options 参数，对应前面的编号。这里我们需要填入’IP 地址’(包含引号，需要英文输入法) 填入对应参数后，点 OK 确认保存 内网设备设置 先将接入网络的设备设置静态地址，再手动设置DHCP选项。 打开DHCP Server→Leases 找到要设置的设备 右键指定设备 设置Make Static 双击指定设备，在DHCP Lease 中General选项下拉找到 DHCP Options，选择添加的Options选项，应用确定即可。 这样设置的好处就是可以设置全局分配 ROS 网关，只将需要经过旁路由的设备才会走旁路由，一来可以避免 NAS 等设备经过代理，二来任你怎么折腾旁路由，家人的设备也不会受到影响。 Options其他参数详情 Options号 Options作用 1 设置子网掩码选项。 3 设置网关地址选项。 6 设置DNS服务器地址选项。 12 设置域名选项。 15 设置域名后缀选项。 33 设置静态路由选项。该选项中包含一组有分类静态路由（即目的地址的掩码固定为自然掩码，不能划分子网），客户端收到该选项后，将在路由表中添加这些静态路由。如果存在Option121，则忽略该选项。 44 设置NetBios服务器选项。 46 设置NetBios节点类型选项。 50 设置请求IP选项。 51 设置IP地址租约时间选项。 52 设置Option附加选项。 53 设置DHCP消息类型。 54 设置服务器标识。 55 设置请求参数列表选项。客户端利用该选项指明需要从服务器获取哪些网络配置参数。该选项内容为客户端请求的参数对应的选项值。 58 设置续约T1时间，一般是租期时间的50%。 59 设置续约T2时间。一般是租期时间的87.5%。 60 设置厂商分类信息选项，用于标识DHCP客户端的类型和配置。 61 设置客户端标识选项。 66 设置TFTP服务器名选项，用来指定为客户端分配的TFTP服务器的域名。 67 设置启动文件名选项，用来指定为客户端分配的启动文件名。 77 设置用户类型标识。 121 设置无分类路由选项。该选项中包含一组无分类静态路由（即目的地址的掩码为任意值，可以通过掩码来划分子网），客户端收到该选项后，将在路由表中添加这些静态路由。 148 EasyDeploy中Commander的IP地址。 149 SFTP和FTPS服务器的IP地址。 150 设置TFTP服务器地址选项，指定为客户端分配的TFTP服务器的地址。 ","link":"https://ziznah.github.io/post/mikrotik-zhi-ding-bu-tong-wang-guan-yu-dns/"},{"title":"使用nacos做配置中心","content":"使用nacos做配置中心 本示例针对指定的nacos版本以及springcloud版本 （小版本可对照尝试，大版本建议查看官方文档） spring-cloud-alibaba ：2.1.0.RELEASE spring-cloud-starter-alibaba-nacos-config：2.1.0.RELEASE 依赖 在pom.xml 文件，引入 Nacos Config Starter。 &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; 配置 Nacos Config 在/src/main/resources/下新建bootstrap.properties配置文件 配置文件中进行如下配置 spring.application.name=微服务名 spring.cloud.nacos.config.server-addr=nacos server地址:8848 注解 使用@Value来获取配置中的数据 使用@RefreshScope打开动态刷新功能 如下： @RefreshScope class SampleController { @Value(&quot;${user.name}&quot;) String userName; @Value(&quot;${user.age}&quot;) int age; } 使用 在Nacos Config中动态使用修改配置： 在配置中心默认添加一个 数据集（Data Id）应用名.properties ，group 默认为 DEFAULT_GROUP，可以通过 spring.cloud.nacos.config.group 配置。 配置格式选择 Properties。 配置内容中使用Properties格式进行配置更改或者添加。 注意事项 如果Nacos Config和配置文件中有相同的配置信息，则Nacos Config中的数据有最高优先级。 ","link":"https://ziznah.github.io/post/nacos-config/"},{"title":"SpringCloud-OpenFeign远程调用","content":"SpringCloud-OpenFeign远程调用 1. 引入open-feign 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 2. 声明远程接口 编写一个接口，告诉 SpringCloud 这个接口需要调用远程服务 （将需要调用的方法完整签名复制到这个接口中） 定义的接口： //路径需要使用nacas注册中心中的名称 @FeignClient(name = &quot;要调用微服务的applicationName&quot;) public interface xxxFeignService{ // 远程调用的路径需要完整 @RequestMapping(&quot;/aaa/bbb&quot;) public R aaabbb(); } 被调用的微服务的方法： @RequestMapping(&quot;aaa&quot;) public class xxxController { @RequestMapping(&quot;/bbb&quot;) public R xxx(){ return &quot;&quot;; } } 3. 开启远程调用功能 @EnableFeignClients(basePackages = &quot;xxx.feign&quot;) 例子： @EnableFeignClients(basePackages = &quot;xxx.feign&quot;) //这里写定义接口的包地址引用 @SpringBootApplication @EnableDiscoveryClient public class xxxApplication { public static void main(String[] args) { SpringApplication.run(xxxApplication.class, args); } } 问题 由于Spring Cloud Feign在Hoxton.M2 RELEASED版本之后不再使用Ribbon而是使用spring-cloud-loadbalancer，所以不引入spring-cloud-loadbalancer会报错。 解决办法： 加入spring-cloud-loadbalancer依赖，并且在nacos中排除ribbon依赖。 &lt;!--nacos服务注册--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;!--排除ribbon--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--引入spring-cloud-starter-loadbalancer--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; ","link":"https://ziznah.github.io/post/openfeign/"},{"title":"快速搭建豆瓣刮削器代理","content":" 由于公用的搜刮器用的是同一个代理，随着大量的用户访问，导致代理挂了，搭建自己的代理实现搜刮自由。 在cloudflare建立workers应用 打开 https://dash.cloudflare.com/sign-up，注册自己的账号。 在个人主页中，右侧点击建立“workers”应用。 点击“创建worker”。 删除内置代码，复制下面的内容。 addEventListener('fetch', event =&gt; { event.respondWith(handleRequest(event.request)) }) async function handleRequest(request) { targetUrl = request.url.split('-----')[1] return await fetch(targetUrl) } 点击“保存并部署”。 PS:可以workers可以自定义名称，后面要使用。 群晖SSH安装 安装： 1. ssh 登录群晖系统 2. 执行wget https://raw.githubusercontent.com/jswh/synology_video_station_douban_plugin/master/install.sh 3. 执行sudo bash install.sh uninstall （第一次安装可以跳过这个步骤） 4. 执行sudo bash install.sh install 'http://douban.abc.workers.dev' http://douban.abc.workers.dev 为上方workers部署到的域名地址 卸载 1. ssh 登录群晖系统 2. 执行wget https://raw.githubusercontent.com/jswh/synology_video_station_douban_plugin/master/install.sh 3. 执行sudo bash install.sh uninstall 更改演员表中英文为中文 找到douban.php文件 douban.php在以下文件夹中 /var/packages/VideoStation/target/plugins/syno_file_assets 添加替换代码 foreach ($movie_data-&gt;{$fn}() as $item) { if (!in_array($item['name'], $data[$key])) { #在此位置添加以下代码 $item['name']= explode(&quot; &quot;, $item['name']); array_push($data[$key], format_the_name($item['name'])); } } 群晖访问GitHub 上方下载脚本的时候，如果访问不了GitHub，解决方式是以 root 权限修改群晖的 hosts 文件，重新指向刮削器可以正常访问的 IP 地址即可。 首先先用 SSH 工具以 root 权限登录群晖。然后输入vim /etc/hosts打开 hosts 文件 英文输入法下在键盘上按下i键进入编辑模式，然后添加以下内容 140.82.114.3 github.com 185.199.108.153 assets-cdn.github.com 199.232.69.194 github.global.ssl.fastly.net 然后按键盘上的ESC键退出编辑，再输入:wq 保存并退出编辑器。 ","link":"https://ziznah.github.io/post/kuai-su-da-jian-dou-ban-gua-xue-qi-dai-li/"},{"title":"视频硬解图示","content":" 由于现使用Android TV盒子过于卡顿，于是购买HTPC 小主机想法油然而生，主要用来不时之需来使用一下，毕竟APPLE TV 4K(二代)已经在路上。主要用途还是看视频，能够轻松胜任视频硬解，看到贴吧有大佬制作了一个显卡硬解表格，由此再集合一下。 大佬原帖： 原帖 核显 AMD显卡 NVIDIA显卡 核显对应的部分CPU ","link":"https://ziznah.github.io/post/shi-pin-ying-jie-tu-shi/"},{"title":"Ubuntu 远程root登录","content":"Ubuntu远程root登录 低价购买了三年的腾讯云vps，尝试远程ssh登录的时候，发现无法使用root用户登录，只能使用默认的用户名，这就大大增加了使用时候的操作步骤，于是就尝试给Ubuntu赋予远程root使用的权限。 增加一个root密码 默认主机是没有root密码，我们这里新增一个root的密码。 建议使用相同但不简单的密码，防止忘记也防止太简单出现数据损失。 sudo passwd root 这里需要输入两次密码，出现修改成功即可。 修改sshd配置 sshd中默认不使用ROOT登录，修改sshd的配置文件来开启一下。 修改sshd的配置文件 sudo vim /etc/ssh/sshd_config 修改 PermitRootLogin 的默认参数 这里我在原属性下面添加相同的属性，保留了原来的配置内容。 重启ssh服务 sudo service ssh restart 自此，这台vps主机就可以远程进行root登录。 ","link":"https://ziznah.github.io/post/21/"},{"title":"关于WIN10下启动应用程序出现MSVCR110.dll缺失的解决办法","content":"关于WIN10下启动应用程序出现MSVCR110.dll缺失的解决办法 由于更换了电脑硬件，介于有工作环境的原因，没有彻底的重装系统，而是使用WIN10自带的重置，导致重装其他软件的时候，打开出现XXX.dll缺失无法启动应用程序。 问题 安装xshell之后，启动时出现： 由于找不到MSVCR110.dll，无法继续执行代码。重新安装程序可能会解决此问题。由于找不到 MSVCR110.dll，无法继续执行代码。重新安装程序可能会解决此问题。 由于找不到MSVCR110.dll，无法继续执行代码。重新安装程序可能会解决此问题。 由于找不到MSVCP110.dll，无法继续执行代码。重新安装程序可能会解决此问题。由于找不到 MSVCP110.dll，无法继续执行代码。重新安装程序可能会解决此问题。 由于找不到MSVCP110.dll，无法继续执行代码。重新安装程序可能会解决此问题。 寻找解决办法 在微软的社区交流中发现遇到相同问题的用户，Microsoft 代理 审阅人给出的解决方法是： 我根据解决办法，安装了指定版本的VC++运行库 重新运行xshell但是还是出现了文件缺失的提示，我将软件重装以及电脑重启，均无法解决此问题。 最终方法 如果你的电脑系统是X64的，则需要将 vcredist_x64.exe 以及 vcredist_x86.exe 全部勾选并安装，再次打开应用程序解决报错问题。 微软Visual C++ 运行库下载地址： https://www.microsoft.com/en-us/download/details.aspx?id=30679 ","link":"https://ziznah.github.io/post/20/"},{"title":"NetflixDNS解锁","content":"NetflixDNS解锁 由于Netflix的版权问题，使用一般的代理服务跨区看剧时会被 Netflix 检测到并阻止，当我们使用的vps不能观看Netflix的时候，我们可以选择购买便宜大碗的vps来辅助解锁不能查看Netflix的vps。 准备工作 正式开始之前，我们需要做一些基本的准备，你至少需要这些东西： 支持 Netflix 的代理服务 不支持 Netflix 的代理服务 Netflix订阅 就目前而言，美区应该是目前剧集资源最丰富的地区，但是根据本人亲测，美区的资源并不符合国人的观看风格，个人比较推荐香港。 使用Dnsmasq解锁Netflix（奈飞）流媒体服务 这里借助了萌精灵 的脚本实现，这里感谢萌精灵。 安装方法： 支持 Netflix 的代理vps安装 wget --no-check-certificate -O dnsmasq_sniproxy.sh https://raw.githubusercontent.com/myxuchangbin/dnsmasq_sniproxy_install/master/dnsmasq_sniproxy.sh &amp;&amp; bash dnsmasq_sniproxy.sh -f 卸载方法： wget --no-check-certificate -O dnsmasq_sniproxy.sh https://raw.githubusercontent.com/myxuchangbin/dnsmasq_sniproxy_install/master/dnsmasq_sniproxy.sh &amp;&amp; bash dnsmasq_sniproxy.sh -u 使用方法： 将不支持 Netflix 的代理VPS的DNS地址修改为支持 Netflix 的代理vps的IP就可以了，如果不能用，记得只保留一个DNS地址试一下。 ⚠️：防止滥用，建议不要随意公布IP地址，或使用防火墙做好限制工作。 调试排错： 确认sniproxy有效运行 重启sni命令：systemctl restart sniproxy 如果sni不在运行，可检查配置/etc/sniproxy.conf，避免ss、nginx或者其他程序监听80,443，可将其配置文件的80更改为801等。 443端口必须给sni监听放行，查看：netstat -tlunp|grep 443 确认防火墙放行443,53 调试可直接关闭防火墙 systemctl stop firewalld.service 阿里云/谷歌云/AWS等外部防火墙放行 可通过其他服务器 telnet vpsip 53 以及 telnet vpsip 443 进行测试 解析域名 尝试用其他服务器配置完毕dns后，解析域名：nslookup netflix.com 判断IP是否是NETFLIX代理机器IP 如果不存在nslookup命令，CENTOS安装：yum install -y bind-utils，DEBIAN安装：apt-get -y install dnsutils 一键脚本修改推荐修改方式： 一键脚本很多都会自带dns服务，会影响流媒体的dns解锁。 修改方式： vi /etc/v2ray/config.json 找到DNS &quot;dns&quot;: { &quot;servers&quot;: [ { &quot;address&quot;: &quot;xxx.xxx.xxx.xxx&quot;, //此处为支持 Netflix 的代理VPS &quot;port&quot;: 53, &quot;domains&quot;: [ &quot;domain:netflix.com&quot;, &quot;domain:netflix.net&quot;, &quot;domain:nflximg.net&quot;, &quot;domain:nflxvideo.net&quot;, &quot;domain:nflxso.net&quot;, &quot;domain:nflxext.com&quot; ] }, &quot;localhost&quot; ] } 修改配置完成以后，请重启你的V2RAY服务，或是重启VPS。 使用分流，让不同的流媒体走不同的DNS 修改方法： &quot;dns&quot;: { &quot;servers&quot;: [ { &quot;address&quot;: &quot;支持Netflix的代理VPS&quot;, &quot;port&quot;: 53, &quot;domains&quot;: [ &quot;domain:netflix.com&quot;, &quot;domain:netflix.net&quot;, &quot;domain:nflximg.net&quot;, &quot;domain:nflxvideo.net&quot;, &quot;domain:nflxso.net&quot;, &quot;domain:nflxext.com&quot; ] }, { &quot;address&quot;: &quot;支持的代理VPS&quot;, &quot;port&quot;: 53, &quot;domains&quot;: [ &quot;domain:gamer2-cds.cdn.hinet.net&quot;, &quot;domain:gamer-cds.cdn.hinet.net&quot;, &quot;domain:gamer.com.tw&quot;, &quot;domain:i2.bahamut.com.tw&quot;, &quot;domain:app-measurement.com&quot; ] }, { &quot;address&quot;: &quot;支持的代理VPS&quot;, &quot;port&quot;: 53, &quot;domains&quot;: [ &quot;domain:bilibili.com&quot; ] }, &quot;localhost&quot; ] } 域名规则 Netflix netflix.com netflix.net nflximg.net nflximg.com nflxvideo.net nflxso.net nflxext.com Spotify scdn.co spotify.com spoti.fi bilibili bilibili.com 动画疯 gamer-cds.cdn.hinet.net gamer2-cds.cdn.hinet.net gamer.com.tw i2.bahamut.com.tw app-measurement.com Line lin.ee line.me linenaver.jp line-apps.com line-cdn.net line-scdn.net linetv.tw cloudfront.net Fox+ fox.com foxdng.com foxnow.com foxplus.com foxplay.com BBC bbc.co bbc.com co.uk llnwd.net akamaized.net Hulu hulu.com huluim.com hbo(美区) hbonow.com hbogo.com hbomax.com hbo.com disney disney.com disneyjunior.com disneyplus.com disney-plus.net dssott.com bamgrid.com amazonaws.com go.com ","link":"https://ziznah.github.io/post/netflixdns-jie-suo/"},{"title":"ROS双软路由使用jump实现公网端口转发","content":" 由于使用了双软路由，ROS上设置upnp，端口不能实现自动转发，所以使用ROS的jump方式来实现这个功能。 首先在ROS功能界面打开 IP → Firewall → NAT 添加一个 NAT 规则 (设置jump) 1️⃣ General 设置 2️⃣ Action 设置 设置需要的端口转发 1️⃣ 添加一个 NAT 规则 (General 设置) 2️⃣ Action 设置 到此端口转发就设置完成。 番外 由于公网每次拨号，可能导致公网地址会发生改变，这里使用ROS的脚本来实现自动设置JUMP里面的公网地址。 1️⃣ 在ROS界面 System → scripts 添加一个脚本 2️⃣ 设置脚本 script脚本代码： :global addold :global addnew :set addnew [/interface get [/interface find name=&quot;pppoe-out1&quot;] running] :if ($addnew=true) do={ :set addold [/ip address get [/ip address find dynamic=yes interface=&quot;pppoe-out1&quot;] address] :set addold [:pick $addold 0 ([:len $addold ] -3)] /ip firewall nat set [/ip firewall nat find comment=&quot;dynamic_nat&quot;] dst-address=$addold } 3️⃣ 设置一个定时Profile ROS界面 → PPP → Profiles 添加一个新的Profile 设置Profiles 设置 Scripts profile脚本代码： delay 3s :execute &quot;dynamic_nat&quot; 🌈以上，公网端口转发的jump设置全部设置完毕，如果过程有错误的地方，还请各位指教一起讨论，谢谢。💨 ","link":"https://ziznah.github.io/post/19/"},{"title":"docker开机自启","content":"docker开机自启 一、docker服务设置自动启动 适用于yum安装的各种服务 查看已启动的服务 systemctl list-units --type=service 查看是否设置开机启动 systemctl list-unit-files | grep enable 设置开机启动 systemctl enable docker.service 关闭开机启动 systemctl disable docker.service 二、docker容器设置自动启动 启动时加 --restart=always docker run tomcat -it -d -p 8080:8080 --restart=always 如果已经运行过的项目 针对：已经启动的项目，使用update更新 docker update --restart=always imagesID restart参数的启动选项 Flag Description no 不自动重启容器. (默认value) on-failure 容器发生error而退出(容器退出状态不为0)重启容器 unless-stopped 在容器已经stop掉或Docker stoped/restarted的时候才重启容器 always 在容器已经stop掉或Docker stoped/restarted的时候才重启容器 转载至：秋寻草 ","link":"https://ziznah.github.io/post/16/"},{"title":"Docker安装GUI图形化界面（Portainer）","content":"Docker安装GUI图形化界面（Portainer） Portainer是一个开源、轻量级Docker管理用户界面，基于Docker API，提供状态显示面板、应用模板快速部署、容器镜像网络数据卷的基本操作（包括上传下载镜像，创建容器等操作）、事件日志显示、容器控制台操作、Swarm集群和服务等集中管理和操作、登录用户管理和控制等功能。功能十分全面，基本能满足中小型单位对容器管理的全部需求。 快速入门 1.官网 https://www.portainer.io/installation/ 2.使用docker安装portainer 1.搜索portainer docker search portainer 2.将镜像拉取到本地 docker pull portainer/portainer 3.运行镜像 docker run -d -it --name portainerUI -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer 注意：这里如果使用单机版，一定要使用 -v /var/run/docker.sock:/var/run/docker.sock，否则在进入WEBUI的时候创建会出现问题，这里 volume也可使用官方教程，这里将运行代码一并贴入。 docker volume create portainer_data docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer 官方这里创建了一个portainer_data的文件夹用于存储数据，大家按需运行即可。 3.访问Portainer 1.创建用户 打开浏览器输入 ip:端口号，这里ip是Linux的地址，端口号为启动的时候映射的端口。 2.连接docker环境 3.进入Portainer管理 ","link":"https://ziznah.github.io/post/15/"},{"title":"GateWay自定义全局GlobalFilter","content":"GateWay自定义全局GlobalFilter 1.实现两个接口 GlobalFilter 用于自定义过滤器，例如进行Token验证 Ordered Spring提供了Ordered这个接口，来处理相同接口实现类的优先级问题。 import lombok.extern.slf4j.Slf4j; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.Ordered; import org.springframework.http.HttpStatus; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; import java.util.Date; @Component @Slf4j public class MyLogGateWayFilter implements GlobalFilter, Ordered { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { //打印输出信息 log.info(&quot;************come in MyLogGateWayFilter&quot; + new Date()); //获取request中的参数 String name = exchange.getRequest().getQueryParams().getFirst(&quot;name&quot;); //判断参数的信息 if(name ==null){ log.info(&quot;************用户名为null，非法用户，/(ㄒoㄒ)/~~&quot;); exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE); return exchange.getResponse().setComplete(); } return chain.filter(exchange); } @Override public int getOrder() { return 0; } } 2. 使用CMD验证 遵循过滤器中的规则 不遵循过滤器中的规则 3.网页端测试 遵循过滤器中的规则 不遵循过滤器中的规则 结论：自定义Filter类似SpringMVC中的Filter，GlobalGilter 全局过滤器接口与 GatewayFilter 网关过滤器接口具有相同的方法定义。全局过滤器是一系列特殊的过滤器，会根据条件应用到所有路由中。网关过滤器是更细粒度的过滤器，作用于指定的路由中。 ","link":"https://ziznah.github.io/post/13/"},{"title":"微服务中使用GateWay实现保护、增强和控制对于 API 服务的访问。","content":"微服务中使用GateWay实现保护、增强和控制对于 API 服务的访问。 网关的角色是作为一个 API 架构，用来保护、增强和控制对于 API 服务的访问。 API 网关是一个处于应用程序或服务（提供 REST API 接口服务）之前的系统，用来管理授权、访问控制和流量限制等，这样 REST API 接口服务就被 API 网关保护起来，对所有的调用者透明。因此，隐藏在 API 网关后面的业务系统就可以专注于创建和管理服务，而不用去处理这些策略性的基础设施。 简单使用 三个概念 注：上图引用CSDN博主AlgoRain，这里致谢一下大佬详细的讲解。 springcloud中使用 1.新建Module 添加一个新的Module，cloud-gateway-gateway9527（名称按照自己喜好） 2.添加POM依赖 &lt;dependencies&gt; &lt;!--gateway--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Eureka client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--导入自己定义的api通用包--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ziznah.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--一般基础配置类--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.添加YML文件 #配置端口 server: port: 9527 spring: application: name: cloud-gateway cloud: gateway: routes: - id: payment_routh #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 uri: http://localhost:8001 #匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - id: payment_routh2 #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 uri: http://localhost:8001 #匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 #注册进服务中心，这里使用的是eureka eureka: instance: hostname: cloud-gateway-service client: #服务提供者provider注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://localhost:7001/eureka/ 4.主启动类 import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient @EnableDiscoveryClient public class GateWayMain9527 { public static void main(String[] args) { SpringApplication.run(GateWayMain9527.class,args); } } 使用配置类来简单使用GateWay 将http://localhost:9527/guonei转发到百度的新闻网中的国内信息 import org.springframework.cloud.gateway.route.RouteLocator; import org.springframework.cloud.gateway.route.builder.RouteLocatorBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class GateWayConfig { /** * 配置一个id为route-name的路由规则， * 当访问地址http://localhost:9527/guonei时会自动转发到地址：http://news.baidu.com/guonei * @param routeLocatorBuilder * @return */ @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder routeLocatorBuilder){ //获取网关的routes RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); //设置网关的内容 routes.route(&quot;path_route_ziznah&quot;,r -&gt; r.path(&quot;/guonei&quot;).uri(&quot;http://news.baidu.com/guonei&quot;)).build(); //返回内容 return routes.build(); } } 实现动态路由 多个服务提供者进行提供服务，使用动态路由来到达负载均衡 1.YML server: port: 9527 spring: application: name: cloud-gateway cloud: gateway: #开启动态创建路由的功能 discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - id: payment_routh2 #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 eureka: instance: hostname: cloud-gateway-service client: #服务提供者provider注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://localhost:7001/eureka/ 注：需要注意的是uri的协议lb，表示启用Gateway的负载均衡功能，lb://serverName是spring cloud gatway在微服务中自动为我们创建的负载均衡uri。 predicates断言不同类型 1.After YML文件 # 断言，路径相匹配的进行路由 predicates: - After=2020-07-06T16:43:08.146+08:00[Asia/Shanghai] 上述的时间地址可使用Java中time的api来获取： import java.time.ZoneId; import java.time.ZonedDateTime; public class T2 { public static void main(String[] args) { //获取默认时区 ZonedDateTime zdt = ZonedDateTime.now(); System.out.println(zdt); //通过指定时区获取当前时间 ZonedDateTime now = ZonedDateTime.now(ZoneId.of(&quot;America/New_York&quot;)); System.out.println(now); } } 2.Before 方法同After 3.Between 方法同After 4.Cookie YML文件 # 断言，路径相匹配的进行路由 predicates: - Cookie=ceshi,admin Windows中CMD窗口使用curl命令进行http请求 不带Cookie进行访问测试。 带Cookie进行访问测试。 5.Header YML文件 # 断言，路径相匹配的进行路由 predicates: - Header=X-Request-Id, \\d+ #请求头要有X-Request-Id属性，并且值为正数的正则表达式。 使用CMD的curl命令测试 带Header 不带Header 带错误的Header信息 6.Host YML # 断言，路径相匹配的进行路由 predicates: - Host=**.ceshi.com 使用CMD的curl命令测试 带Host测试 不带Host测试 带错误Host测试 7.Method YML # 断言，路径相匹配的进行路由 predicates: - Method=GET 8.Path 9.Query 10.Weight ","link":"https://ziznah.github.io/post/12/"},{"title":"参考RoundRobinRule代码模拟负载均衡","content":"参考RoundRobinRule代码模拟负载均衡 1.定义一个LoadBalancer接口 获取服务器集群上能够提供服务的机器数量 public interface Loadbalancer { /** * 获取服务器集群上能够提供服务的机器数量 * @param serviceInstances * @return */ ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances); } 2.实现LoadBalancer接口中的方法 利用自旋锁，创建获取当前服务调用是第几次访问的方法 实现接口中获取提供服务机器数量的方法，模拟负载均衡算法来达到负载调用服务。 /** * ClassName: MyLB * Description: 参考RoundRobinRule代码模拟负载均衡 * Author: SUGAR * Date: 2020/6/25 16:09 * Version: 1.0 **/ @Component public class MyLB implements Loadbalancer{ private AtomicInteger atomicInteger = new AtomicInteger(0); /** * 获取当前服务调用是第几次访问 * @return */ public final int getAndIncrement(){ int current; int next; do { current = this.atomicInteger.get(); next = current &gt;= 2147483647 ? 0 : current + 1; }while (!this.atomicInteger.compareAndSet(current,next)); System.out.println(&quot;*****访问第&quot; + next + &quot;次！*****&quot;); return next; } /** * 根据第几次访问，模拟负载均衡算法来达到负载调用服务 * 负载均衡算法：rest接口第几次请求数 % 服务器集群总数量 = 实际调用服务器位置下标 * 每次服务启动后rest接口计数从1开始 * @param serviceInstances * @return */ @Override public ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances) { int index = getAndIncrement() % serviceInstances.size(); return serviceInstances.get(index); } } 3.取消LoadBalanced注解 取消ApplicationContextConfig中RestTemplate的get方法的LoadBalanced注解，使用自己模拟的负载均衡。 @Configuration public class ApplicationContextConfig { @Bean // @LoadBalanced 使用自己模拟的负载均衡的方法 public RestTemplate getRestTemplate(){ return new RestTemplate(); } } 4.添加服务提供商提供的controller方法 添加一个获取当前服务提供者端口的方法，用来负载均衡。 @GetMapping(value = &quot;/payment/lb&quot;) public String getPaymentLB() { return serverPort; } 注：这里的方法添加到提供商的controller中。 5.调用者添加controller方法 调用者controller添加调用服务提供商的方法，测试负载均衡 @GetMapping(value = &quot;/consumer/payment/lb&quot;) public String getPayementLB(){ List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(&quot;CLOUD-PAYMENT-SERVICE&quot;); //判断服务是否为有效服务 if(instances == null || instances.size() &lt;= 0){ return null; } ServiceInstance serviceInstance = loadbalancer.instances(instances); URI uri = serviceInstance.getUri(); return restTemplate.getForObject(uri + &quot;/payment/lb&quot;,String.class); } 6.测试 启动对应的服务 查看是否启动成功（模拟提供者集群以及服务器集群） 模拟调用者访问接口 ​ 根据以上调用，后台也打印出相应的调用信息。 ","link":"https://ziznah.github.io/post/11/"},{"title":"Docker中 CMD 与 ENTRYPOINT 保留指令的区别","content":" 编写Dockerfile时，时常看到最后会看到CMD或者ENTRYPOINT 的保留指令，但是他们的意义都为：指定一个容器启动时要运行的命令，那么它们之间的差异在哪里？ 使用curl命令来说明 首先编写两个Dockerfile 使用CMD保留指令。 FROM centos RUN yum install -y curl CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;https://www.baidu.com/&quot; ] 这里 Dockerfile 的名字要求小写，否则会报错invalid argument &quot;cmdCentos&quot; for &quot;-t, --tag&quot; flag: invalid reference format: repository name must be lowercase See 'docker build --help'. 使用ENTRYPOINT保留指令。 FROM centos RUN yum install -y curl ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;https://www.baidu.com/&quot; ] 在docker中进行build进行构建一个新的镜像 构建CMD保留指令的Dockerfile。 构建ENTRYPOINT保留指令的Dockerfile。 运行两个镜像进行对比 运行CMD保留指令的镜像。 运行ENTRYPOINT保留指令的镜像。 这个时候我们发现，两个镜像运行起来没有任何区别，但是重点来了！当我们需要对镜像启动时要运行的命令进行增强的时候。 比如我们还想获取指定网站的头信息。 运行增强后的CMD保留指令的镜像。 运行增强后的ENTRYPOINT保留指令的镜像。 总结 由上述的案例，我们不难发现，在执行Dockerfile中，如果使用了CMD保留指令，那么在执行镜像的时候，我们在其启动命令后面添加OPTION选项的时候，将会覆盖Dockerfile中的上一句指令，造成运行失败。例如： FROM centos RUN yum install -y curl CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;https://www.baidu.com/&quot; ] CMD -i 如果使用ENTRYPOINT保留指令，那么在执行镜像的时候，我们在其启动命令后面添加OPTION选项的时候，会对运行的命令进行“增强”。例如： FROM centos RUN yum install -y curl ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;,&quot;-i&quot;, &quot;https://www.baidu.com/&quot; ] 所以，在实际应用中，是使用CMD还是ENTRYPOINT保留指令，要根据具体的业务要求。 ","link":"https://ziznah.github.io/post/10/"},{"title":"在VMware Workstation上安装CentOS7的网络问题","content":"配置网络 虚拟机CentOS的网络设置 1. 将网络适配器设置为NAT模式 2. Linux中网络设置 cd /etc/sysconfig/network-scripts/，进入CentOS7的网络配置文件下，找到对应的网卡设置，我这里的网卡是ifcfg-ens32，每个人的网卡名称可能不一样，不用在意。 vim ifcfg-ens32 ，打开指定的网卡配置文件，如果系统没有安装 vim，使用 vi 打开即可。 添加的ip、子网掩码、网关，在VMware Workstation中的虚拟网络编辑器中查看。 选择VMnet8，然后NAT设置 IPADDR：为上方的子网IP，建议IP设置为XXX.XXX.XXX.200~XXX.XXX.XXX.250之间 PREFIXO：为上方子网掩码，255.255.255.0即为24 GATEWAY：为上方网关IP，对应填上即可。 DNS1：8.8.8.8 DNS2：8.8.4.4 这里DNS都设置为谷歌的DNS，正常解析即可，其他DNS也可。 ","link":"https://ziznah.github.io/post/9/"},{"title":"Redis","content":" 多能，数据类型丰富，使用Redis，Tair Redis:REmote DIctionary Server(远程字典服务器) 是完全开源免费的，用C语言编写的，遵守BSD协议， 是一个高性能的(key/value)分布式内存数据库，基于内存运行 并支持持久化的NoSQL数据库，是当前最热门的NoSql数据库之一, 也被人们称为数据结构服务器 下载Redis https://redis.io/download 对Redis的理解 Redis是一个开放源代码（BSD许可）的内存中数据结构存储，用作数据库，缓存和消息代理。 KV、Cache、Persistence、... Redis的概述 3V+3高 3V 3高 海量Volume 高并发 多样Variety 高可扩 实时Velocity 高性能 传统关系型数据库 传统的ACID 1、A (Atomicity) 原子性 原子性很容易理解，也就是说事务里的所有操作要么全部做完，要么都不做，事务成功的条件是事务里的所有操作都成功，只要有一个操作失败，整个事务就失败，需要回滚。比如银行转账，从A账户转100元至B账户，分为两个步骤：1）从A账户取100元；2）存入100元至B账户。这两步要么一起完成，要么一起不完成，如果只完成第一步，第二步失败，钱会莫名其妙少了100元。 2、C (Consistency) 一致性 一致性也比较容易理解，也就是说数据库要一直处于一致的状态，事务的运行不会改变数据库原本的一致性约束。 3、I (Isolation) 独立性 所谓的独立性是指并发的事务之间不会互相影响，如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响。比如现有有个交易是从A账户转100元至B账户，在这个交易还未完成的情况下，如果此时B查询自己的账户，是看不到新增加的100元的 4、D (Durability) 持久性 持久性是指一旦事务提交后，它所做的修改将会永久的保存在数据库上，即使出现宕机也不会丢失。 非关系型数据库 CAP C:Consistency（强一致性） A:Availability（可用性） P:Partition tolerance（分区容错性） Redis的安装 Linux版安装 获取Redis的安装包 将安装包放在/usr/local/redis下 解压Redis安装包 tar -zxvf redis-5.0.4.tar.gz 进入Redis目录 cd /usr/local/redis/redis-5.0.4 执行make命令 make 运行make命令时故 意出现的错误解析： ​ 安装gcc yum -y install gcc-c++ 执行make install，检验安装 make install Redis基本使用 更改配置 1.更改redis.conf配置文件 首先备份当前redis.conf文件，修改以下内容。 daemonize yes 启动 安装redis之后，在/usr/local/bin会有redis的启动文件。 执行redis-server /bak/redis/redis.conf，启动redis并使用指定的配置文件。 redis-server /bak/redis/redis.conf 连通测试 执行redis-cli -p 6379来指定端口启动测试。 redis-cli -p 6379 使用ping命令来测试连通，出现PONG即为成功。 可使用ps -ef|grep redis来查看redis的进程。 ps -ef|grep redis 关闭redis 执行redis-cli shutdown。 redis-cli shutdown Redis可能遇到问题 修改配置文件 protected-mode no # 关闭保护模式 daemonize yes # 守护进程模式开启 #bind 127.0.0.1 # 绑定IP按需修改 port 6379 # 端口按需修改 运行并检查端口 #启动服务命令 ./usr/local/bin/redis-server /bak/redis/redis.conf #查看6379端口是否占用 netstat -tunpl | grep 6379 开放防火墙端口 #开放6379端口 /sbin/iptables -I INPUT -p tcp --dport 6379 -j ACCEPT #保存配置 /etc/rc.d/init.d/iptables save #重启服务 /etc/rc.d/init.d/iptables restart #查看端口是否已经开放 /etc/init.d/iptables status Redis启动后杂项基础知识讲解 单进程 单进程模型来处理客户端的请求。对读写等事件的响应 是通过对epoll函数的包装来做到的。Redis的实际处理速度完全依靠主进程的执行效率 Epoll是Linux内核为处理大批量文件描述符而作了改进的epoll，是Linux下多路复用IO接口select/poll的增强版本， 它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。 默认16个数据库 默认16个数据库，类似数组下表从零开始，初始默认使用零号库。 可以使用select &lt;id&gt;来连接指定数据库id DBSIZE Dbsize查看当前数据库的key的数量 DBSIZE 使用keys *可查看当前库中的key keys * FLUSHDB 清空当前库 FLUSHDB FLUSHALL 通杀全部库 FLUSHALL 统一密码管理 索引 Reids索引都是从零开始 默认端口 默认端口是6379 Redis数据类型 Redis的五大数据类型 String（字符串） String（字符串） string是redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。 string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。 string类型是Redis最基本的数据类型，一个redis中字符串value最多可以是512M Hash（哈希，类似java里的Map） Hash（哈希） Redis hash 是一个键值对集合。 Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 类似Java里面的Map&lt;String,Object&gt; List（列表） List（列表） Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。 它的底层实际是个链表 Set（集合） Redis的Set是string类型的无序集合。它是通过HashTable实现实现的。 Zset(sorted set：有序集合) zset(sorted set：有序集合) Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。 redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。 哪里去获得redis常见数据类型操作命令 Http://redisdoc.com/ Redis 键(key) 常用 案例 keys * exists key的名字，判断某个key是否存在。 move key db，移动当前库的key到指定的库中。 expire key，给指定的key设置一个过期时间。 ttl key，查看当前key的过期时间，-1表示永不过期，-2表示已过期。 当key过期的时候，代表当前key的生命周期已经结束，所以在当前库中就不存在这个key。 type key，查看当前的key的类型。 del key，删除当前的key Redis字符串(String) 常用 单值单value 案例 set key value，设置一个K,V get key，获取当前key的value值。 append key value，在指定key的value值后添加指定的值。 strlen key，查询当前key的长度。 incr key，对当前的key进行递增。 decr key，对当前的key进行递减。 incrby key num，对当前的key进行指定数字的递增。 decrby key num，对当前的key进行指定数字的递减。 **注意：**一定要是数字才能进行加减。 getrange key start end，获取当前key字符串的指定长度内容。 setrange key index str，设置当前key字符串指定下标开始，设置str内容。 setex key second valuesetex(set with expire)，设置K,V，并设置到期时间。 setnx key value，setnx(set if not exist)，只有当前key不存在的时候，设置key的值。 mset key1 value1 key2 value2 key3 value3，设置多个K,V。 mget key1 key2 key3，获取多个指定key的值。 msetnx key1 value1 key2 value2 key3 value3，设置多个值，当设置key不存在时，设置指定key值，如果一个不存在，则都不设置。 Redis列表(List) 常用 单值多value 案例 lpush key value1 [value2]，将一个或多个值插入到列表头部。 rpush key value1 [value2]，在列表中添加一个或多个值 lrange key start end，获取列表指定范围内的元素 lpop key，移除并获取列表的第一个元素 rpop key，移除并获取列表最后一个元素。 lindex key index，根据下标，查询执行列表中的数据。 llen key，查询指定列表的长度 lrem key count value，移除指定列表指定数量的值。 ltrim key start end，截取指定列表的指定下标内容，然后赋值给这个列表。 rpoplpush source destination，移除列表的最后一个元素，并将该元素添加到另一个列表并返回。 lset key index value，通过索引设置列表元素的值。 linsert key before|after pivot value，在列表的元素前或者后插入元素。 Redis集合(Set) 常用 单值多value 案例 sadd key member1 [member2]，向集合添加一个或多个成员。 smembers key，返回集合中的所有成员 sismember key member，判断 member 元素是否是集合key的成员。 scard key，获取集合的成员数 srem key member1 [member2]，移除集合中一个或多个成员 srandmember key [count]，返回集合中一个或多个随机数。 spop key，移除并返回集合中的一个随机元素 smove key1 key2 member，将member元素从key1集合移动到key2集合。 数学集合类 sdiff key1 [key2]，返回给定所有集合的差集。（在第一个set里面而不在后面任何一个set里面的项） sinter key1 [key2]，返回给定所有集合的交集。 sunion key1 [key2]，返回所有给定集合的并集。 Redis哈希(Hash) 常用 KV模式不变，但V是一个键值对。 案例 hset key field value，将哈希表key中 的字段field的值设为value。 hget key field，获取存储在哈希表中指定field字段的值。 hmset key field1 value1 [field2 value2]，同时将多个field-value(域-值)对设置到哈希表key中。 hgetall key，获得存储在哈希表中指定key的所有字段和值。 hdel key field，删除存储在哈希表中key 指定字段。 hexists key field，查询存储在哈希表中指定字段是否存在 hkeys key，获取所有哈希表中的字段 hvals keys，获取哈希表中所有的值。 hincrby key field increment，为哈希表key中的指定字段的整数值加上增量increment。 hincrbyfloat key field increment，为哈希表中的指定字段的浮点数值加上增量increment。 hsetnx key field value，只有在字段field不存在时，设置哈希表字段的值。 Redis有序集合Zset(sorted set) 常用 案例 zadd key score1 member1 [score2 member2]，向有序集合添加一个或多个成员，或者更新已存在成员的分数。 zrangebyscore key start end，通过分数返回有序集合指定区间内的成员。 zrangebyscore key (start end，通过返回有序集合指定区间内(带有(，说明不包含)的成员。 zrem key member，根据对应的value值删除有序集合中的成员元素。 zcard key，获得有序列表中的成员数。 zcount key min max，查询在有序列表中指定区间的成员数。 zrank key value，获取指定成员在有序列表中的下标。 zscore key value，获取有序列表中指定成员的值。 zrevrank key values，逆序获得下标值。 解析配置文件redis.conf 1.它在哪 地址。 进入redis目录下，使用pwd命令来查看当前目录。 为什么拷贝出来单独执行？ 通常为了配置的安全，放置在原文件配置错误，导致无法正常运行。 2.Units单位 3.INCLUDES包含 和其他配置文件一样，可以通过includes包含，redis.conf可以作为总闸，包含其他。 4.GENERAL通用 daemonize 介绍 A、redis.conf配置文件中daemonize守护线程，默认是NO。 B、daemonize是用来指定redis是否要用守护线程的方式启动。 daemonize 设置yes或者no区别 daemonize:yes:redis采用的是单进程多线程的模式。当redis.conf中选项daemonize设置成yes时，代表开启守护进程模式。在该模式下，redis会在后台运行，并将进程pid号写入至redis.conf选项pidfile设置的文件中，此时redis将一直运行，除非手动kill该进程。 daemonize:no: 当daemonize选项设置成no时，当前界面将进入redis的命令行界面，exit强制退出或者关闭连接工具(putty,xshell等)都会导致redis进程退出。 Pidfile 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定。 Port 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字。 Tcp-backlog 文档解释 tcp-backlog 设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。 在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog两个值来达到想要的效果。 Timeout 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能。 Bind 绑定的主机地址 Tcp-keepalive 单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60。 Loglevel 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为notice Logfile 指定日志文件的路径。 Syslog-enabled 是否把日志输出到syslog中。默认是no。 Syslog-ident 指定syslog里的日志标志。默认是redis。 Syslog-facility 指定syslog设备，值可以是USER或LOCAL0-LOCAL7。默认是LOCAL0。 Databases 设置数据库的数量，默认数量为16，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id。 5.SNAPSHOTTING快照 Save save 秒钟 写操作次数 RDB是整个内存的压缩过的Snapshot，RDB的数据结构，可以配置复合的快照触发条件， 默认 是1分钟内改了1万次， 或5分钟内改了10次， 或15分钟内改了1次。 禁用 如果想禁用RDB持久化的策略，只要不设置任何save指令，或者给save传入一个空字符串参数也可以。 如果想即可备份，使用save命令，可执行立即备份功能。 Stop-writes-on-bgsave-error 如果配置成no，表示你不在乎数据不一致或者有其他的手段发现和控制。 rdbcompression rdbcompression：对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用 LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能 rdbchecksum dbfilename dir 6.REPLICATION复制 7.SECURITY安全 访问密码的查看、设置和取消。 8.LIMITS限制 Maxclients 设置redis同时可以与多少个客户端进行连接。默认情况下为10000个客户端。当你 无法设置进程文件句柄限制时，redis会设置为当前的文件句柄限制值减去32，因为redis会为自 身内部处理逻辑留一些句柄出来。如果达到了此限制，redis则会拒绝新的连接请求，并且向这 些连接请求方发出“max number of clients reached”以作回应。 Maxmemory 设置redis可以使用的内存量。一旦到达内存使用上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。如果redis无法根据移除规则来移除内存中的数据，或者设置了“不允许移除”， 那么redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。 但是对于无内存申请的指令，仍然会正常响应，比如GET等。如果你的redis是主redis（说明你的redis有从redis），那么在设置内存使用上限时，需要在系统中留出一些内存空间给同步队列缓存，只有在你设置的是“不移除”的情况下，才不用考虑这个因素。 Maxmemory-policy （1）volatile-lru：使用LRU算法移除key，只对设置了过期时间的键。 （2）allkeys-lru：使用LRU算法移除key。 （3）volatile-random：在过期集合中移除随机的key，只对设置了过期时间的键。 （4）allkeys-random：移除随机的key。 （5）volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key。 （6）noeviction：不进行移除。针对写操作，只是返回错误信息。 Maxmemory-samples 设置样本数量，LRU算法和最小TTL算法都并非是精确的算法，而是估算值，所以你可以设置样本的大小， redis默认会检查这么多个key并选择其中LRU的那个。 9.APPEND ONLY MODE追加 appendonly appendfilename Appendfsync Always：同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好。 Everysec：出厂默认推荐，异步操作，每秒记录 如果一秒内宕机，有数据丢失。 No No-appendfsync-on-rewrite：重写时是否可以运用Appendfsync，用默认no即可，保证数据安全性。 Auto-aof-rewrite-min-size：设置重写的基准值 Auto-aof-rewrite-percentage：设置重写的基准值 Redis的持久化 总体介绍 官网介绍 RDB（Redis DataBase） 官网介绍 是什么： 在指定的时间间隔内将内存中的数据集快照写入磁盘， 也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里。 Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到 一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方 式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。 Fork Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。 Rdb 保存的是dump.rdb文件 配置位置 如何触发RDB快照 配置文件中默认的快照配置 冷拷贝后重新使用 可以cp dump.rdb dump_new.rdb 命令save或者是bgsave Save：save时只管保存，其它不管，全部阻塞 BGSAVE：Redis会在后台异步进行快照操作， 快照同时还可以响应客户端请求。可以通过lastsave 命令获取最后一次成功执行快照的时间 执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义 如何恢复 将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可 CONFIG GET dir获取目录 优势 适合大规模的数据恢复 对数据完整性和一致性要求不高 劣势 在一定间隔时间做一次备份，所以如果redis意外down掉的话，就 会丢失最后一次快照后的所有修改 Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑 如何停止 动态所有停止RDB保存规则的方法：redis-cli config set save &quot;&quot; 小总结 AOF（Append Only File） 官网介绍 是什么： 以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来(读操作不记录)， 只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作 Aof保存的是appendonly.aof文件 配置位置 AOF启动/修复/恢复 正常恢复 启动：设置Yes 修改默认的appendonly no，改为yes 将有数据的aof文件复制一份保存到对应目录(config get dir)。 恢复：重启redis然后重新加载。 异常恢复 启动：设置Yes 修改默认的appendonly no，改为yes。 备份被写坏的AOF文件 修复：Redis-check-aof --fix进行修复 恢复：重启redis然后重新加载 Rewrite 是什么： AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制, 当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩， 只保留可以恢复数据的最小指令集.可以使用命令bgrewriteaof 重写原理 AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)， 遍历新进程的内存中数据，每条记录有一条的Set语句。重写aof文件的操作，并没有读取旧的aof文件， 而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。 触发机制 Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。 优势 每修改同步： appendfsync always 同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好。 每秒同步： appendfsync everysec 异步操作，每秒记录 如果一秒内宕机，有数据丢失 不同步： appendfsync no 从不同步。 劣势 相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb。 Aof运行效率要慢于rdb,每秒同步策略效率较好，不同步效率和rdb相同。 小总结 总结(Which one) 官网建议 RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储。 AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些 命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾. Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大。 只做缓存：如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式。 同时开启两种持久化方式。 在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据, 因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。 RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？ 作者建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)， 快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。 性能建议。 因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。 如果Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。 如果不Enable AOF ，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。新浪微博就选用了这种架构。 Redis的事务 是什么 可以一次执行多个命令，本质是一组命令的集合。一个事务中的 所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞。 官网 能干嘛 一个队列中，一次性、顺序性、排他性的执行一系列命令。 怎么玩 常用命令 Case1：正常执行 Case2：放弃事务 Case3：全体连坐 Case4：冤头债主 Case5：watch监控 悲观锁/乐观锁/CAS(Check And Set) 悲观锁 悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁 乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量， 乐观锁策略:提交版本必须大于记录当前版本才能执行更新。 CAS 初始化信用卡可用余额和欠额 无加塞篡改，先监控再开启multi，保证两笔金额变动在同一个事务内。 有加塞篡改。 unwatch 一旦执行了exec之前加的监控锁都会被取消掉了 小结 Watch指令，类似乐观锁，事务提交时，如果Key的值已被别的客户端改变， 比如某个list已被别的客户端push/pop过了，整个事务队列都不会被执行。 通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化， EXEC命令执行的事务都将被放弃，同时返回Nullmulti-bulk应答以通知调用者事务执行失败。 3阶段 开启： 以MULTI开始一个事务。 入队： 将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面 执行： 由EXEC命令触发事务 3特性 单独的隔离操作： 事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 没有隔离级别的概念： 队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行， 也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题 不保证原子性： redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 Redis的发布订阅 是什么 进程间的一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。 订阅/发布消息图 命令 案例 先订阅后发布后才能收到消息， 可以一次性订阅多个，SUBSCRIBE c1 c2 c3 消息发布，PUBLISH c2 hello-redis 订阅多个，通配符*， PSUBSCRIBE new* 收取消息， PUBLISH new1 redis2015。 Redis的复制(Master/Slave) 是什么 官网 行话： 也就是我们所说的主从复制，主机数据更新后根据配置和策略， 自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主 能干嘛 读写分离 容灾恢复 怎么玩 配从(库)不配主(库) 从库配置：slaveof 主库IP 主库端口 每次与master断开之后，都需要重新连接，除非你配置进redis.conf文件 Info replication 修改配置文件细节操作 拷贝多个redis.conf文件 开启daemonize yes Pid文件名字 指定端口 Log文件名字 Dump.rdb名字 常用3招 一主二仆 Init 一个Master两个Slave 日志查看 主机日志 备机日志 info replication 主从问题演示 切入点问题？slave1、slave2是从头开始复制还是从切入点开始复制?比如从k4进来，那之前的123是否也可以复制 从机是否可以写？set可否？ 主机shutdown后情况如何？从机是上位还是原地待命 主机又回来了后，主机新增记录，从机还能否顺利复制？ 其中一台从机down后情况如何？依照原有它能跟上大部队吗？ 薪火相传 上一个Slave可以是下一个slave的Master，Slave同样可以接收其他 slaves的连接和同步请求，那么该slave作为了链条中下一个的master, 可以有效减轻master的写压力 中途变更转向:会清除之前的数据，重新建立拷贝最新的 Slaveof 新主库IP 新主库端口 反客为主 SLAVEOF no one 使当前数据库停止与其他数据库的同步，转成主数据库。 复制原理 Slave启动成功连接到master后会发送一个sync命令 Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。 增量复制：Master继续将新的所有收集到的修改命令依次传给slave,完成同步 但是只要是重新连接master,一次完全同步（全量复制)将被自动执行 哨兵模式(sentinel) 是什么 反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库 怎么玩(使用步骤) 调整结构，6379带着80、81 自定义的/myredis目录下新建sentinel.conf文件，名字绝不能错 配置哨兵,填写内容 sentinel monitor 被监控数据库名字(自己起名字) 127.0.0.1 6379 1 上面最后一个数字1，表示主机挂掉后salve投票看让谁接替成为主机，得票数多少后成为主机 启动哨兵 Redis-sentinel /myredis/sentinel.conf 上述目录依照各自的实际情况配置，可能目录不同 正常主从演示 原有的master挂了 投票新选 重新主从继续开工,info replication查查看 问题：如果之前的master重启回来，会不会双master冲突？ 一组sentinel能同时监控多个Master 复制的缺点 复制延时 由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。 ","link":"https://ziznah.github.io/post/8/"},{"title":"Linux系统下实现远程连接MySQL数据库","content":" MySQL默认root用户只能本地访问，不能远程连接管理mysql数据库。 步骤 1. 在服务器端开启远程访问 首先进入mysql数据库，然后输入下面两个命令： grant all privileges on *.* to 'root'@'%' identified by '123456'; flush privileges; 第一个*是数据库，可以改成允许访问的数据库名称 第二个 是数据库的表名称，代表允许访问任意的表 root代表远程登录使用的用户名，可以自定义 %代表允许任意ip登录，如果你想指定特定的IP，可以把%替换掉就可以了 password代表远程登录时使用的密码，可以自定义 flush privileges;这是让权限立即生效 2. 修改my.cnf配置文件 这个是mysql的配置文件，如果你无标题文章找不到在哪里的话，可以输入find /* -name my.cnf找到 通过vim编辑该文件，找到bind-address = 127.0.0.1这一句，然后在前面加个#号注释掉，保存退出。 3. 重启服务 service mysql restart 4. 在本地远程连接 在终端输入： mysql -h 服务器ip地址 -P 3306 -u root -p 然后输入密码即可。 root是第1点设置的用户名，密码也是第1点设置的密码 ","link":"https://ziznah.github.io/post/7/"},{"title":"Tomcat添加SSL证书实现安全","content":" 将网站域名申请SSL证书，并把证书配置在Tomcat中，实现进入网站即可跳转https，实现网站安全。 1.下载证书并放置到tomcat安装目录下 在tomcat安装目录下创建一个cert文件夹，将下载的证书中一个jks后缀的证书和一个txt后缀的密码文件上传到tomcat安装目录下 mkdir /usr/local/tomcat/apache-tomcat-8.5.51/cert 2.配置server.xml 打开server.xml文件，设置配置文件 vim /usr/local/tomcat/apache-tomcat-8.5.51/conf/server.xml 找到Connector标签将8080端口后面的 redirectPort=&quot;8443&quot; 改为 redirectPort=&quot;443&quot; 找到下面SSL/TLS标签把注释的Connector标签打开并添加certificateKeystorePassword属性，里面的值填写下载的密码txt文件里面的内容。 3.配置web.xml文件 打开tomcat安装目录下的conf文件夹中的web.xml文件 vim /usr/local/tomcat/apache-tomcat-8.5.51/conf/web.xml 拉到最下面，找到welcome-file-list标签，在后面添加以下内容 &lt;login-config&gt; &lt;!-- Authorization setting for SSL --&gt; &lt;auth-method&gt;CLIENT-CERT&lt;/auth-method&gt; &lt;realm-name&gt;Client Cert Users-only Area&lt;/realm-name&gt; &lt;/login-config&gt; &lt;security-constraint&gt; &lt;!-- Authorization setting for SSL --&gt; &lt;web-resource-collection &gt; &lt;web-resource-name &gt;SSL&lt;/web-resource-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/web-resource-collection&gt; &lt;user-data-constraint&gt; &lt;transport-guarantee&gt;CONFIDENTIAL&lt;/transport-guarantee&gt; &lt;/user-data-constraint&gt; &lt;/security-constraint&gt; 保存退出，将tomcat关闭再次开启。 **进入bin目录** cd /usr/local/tomcat/apache-tomcat-8.5.51/bin ​ 关闭tomcat ./shutdown.sh ​ 启动tomcat ./startup.sh 再次访问网站即可成功安全配置SSL证书到tomcat服务器上。 ","link":"https://ziznah.github.io/post/6/"},{"title":"使用PicGo+GitHub打造最稳定可靠的免费图床","content":"创建自己的GitHub图床 1.创建GitHub图床之前，需要注册/登陆GitHub账号 申请GitHub账号并登陆到GitHub官网。 2.创建Repository 在个人选项栏中点击New repository 添加Repository相关的一些设置 3.生成一个Token用于操作GitHub Repository 在个人栏中选择Settings 点击左侧的Developer settings 点击Personal access tokens为上面创建的Repository创建一个Token 创建一个新的Token，并配置信息。 创建成功复制生成的Token，这里注意：生成要提前复制保存，关闭了就看不到了，只能再次生成一次Token。 配置PicGo 1.下载运行PicGo 在官网下载PicGo，根据自己的操作系统进行下载。 2.配置图床 按照下图进行GitHub图床配置 3.快捷键及相关配置 4.其他相关 使用jsDelivr CDN 加速 Github 仓库的图片 原自定义域名： https://raw.githubusercontent.com/用户名/仓库名/master/images 加速后自定义域名 https://cdn.jsdelivr.net/gh/用户名/仓库名@master ","link":"https://ziznah.github.io/post/5/"},{"title":"Chrome浏览器查找当前的页面线程，并使用CE加载。","content":" 使用CE选项中的过滤器先将所有chrome中的进程过滤出来。 打开chrome的任务管理器，（shift+esc）快捷键直接打开，查看当前页面的进程ID。 这个进程ID是使用了十进制，而CE中的进程选择应用程序名是使用了十六进制。所以找到当前页面的进程ID，然后使用程序员计算器来计算出其对应的十六进制，然后在CE的进程名中找到加载即可。 示例： 由此可以计算出如何在chrome使用了多线程之后，准确的找到当前的页面所在的进程位置。 ","link":"https://ziznah.github.io/post/4/"},{"title":"SSM框架IDEA的配置","content":" 用于IDEA搭建SSM框架的配置环境 1. 设置IDEA的maven项目的架构设置 设置Project Structure，将所缺的Sources，Tests，Resources配置完成，以及web.xml的版本更改为3.1。 2. 创建ssm框架的package，以及对应的包 创建domain，mapper，service，web domain：存放实体类 mapper：存放数据库操作的类 service：存放服务层 web：存放springMVC的servlet控制器，controller文件 3. 在resources文件夹中创建spring以及mybatis文件夹，用于存放对应的文件 resources： spring文件夹：用于存放spring所需的配置文件 applicationContext.xml：用于配置spring的配置信息 springmvc-servlet.xml：用于配置springMVC的配置 mybatis文件夹：用于存放mybatis所需的配置文件 mapper文件夹：用于存放mybatis的sql配置 mybatis-config.xml：用于配置mybatis的全局配置 database.properties：用于配置数据库的配置信息 log4j.xml：用于配置日志的配置信息 4. webapp下的配置 在webapp下搭建缺少的一些环境以及内容 static文件夹：用于存放web工程需要的资源文件 css文件夹：用于存放页面的css文件 js文件夹：用于存放页面的js文件 img文件夹：用于存放页面的img文件 lib文件夹：用于存放页面的lib文件 WEB-INF文件夹下创建views文件夹：存放页面(文件安全) 5. 配置SSM框架所缺少的环境配置 配置pom.xml文件中缺少的ssm框架依赖的jar包 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--配置JavaEE的开发jar包--&gt; &lt;dependency&gt; &lt;groupId&gt;javax&lt;/groupId&gt; &lt;artifactId&gt;javaee-api&lt;/artifactId&gt; &lt;version&gt;8.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!--配置mysql所需的jar包--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.48&lt;/version&gt; &lt;/dependency&gt; &lt;!--配置阿里巴巴的德鲁伊数据源--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;!--配置JSTL--&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--配置mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; &lt;!--配置spring--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--配置springMVC--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--配置spring对数据库支持的jar包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--配置spring整合mybatis需要的jar包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--配置hibernate--&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;6.1.0.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!--配置aop注解--&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.5&lt;/version&gt; &lt;/dependency&gt; &lt;!--配置日志--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;2.11.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 1.配置mybatis-config.xml的内容 &lt;?xml version='1.0' encoding='UTF-8'?&gt; &lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot; &gt; &lt;configuration&gt; &lt;!--全局配置--&gt; &lt;settings&gt; &lt;!--启用缓存--&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; &lt;!--启用日志--&gt; &lt;setting name=&quot;logImpl&quot; value=&quot;LOG4J2&quot;/&gt; &lt;!--启用主键生成策略--&gt; &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;true&quot;/&gt; &lt;!--启用下划线命名自动转驼峰命名--&gt; &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt; &lt;/settings&gt; &lt;/configuration&gt; 2.配置database.properties的数据库配置文件 jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:msql://localhost:3306/bbs jdbc.username=root jdbc.password= 3. 配置log4j.xml的日志配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;Configuration status=&quot;WARN&quot;&gt; &lt;!--日志追加器：日志通过什么方式输出--&gt; &lt;Appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout pattern=&quot;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n&quot; /&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=&quot;debug&quot;&gt; &lt;AppenderRef ref=&quot;Console&quot; /&gt; &lt;/Root&gt; &lt;!-- &lt;logger name=&quot;org.springframework.web&quot; level=&quot;error&quot; &gt;&lt;/logger&gt; --&gt; &lt;/Loggers&gt; &lt;/Configuration&gt; 4.配置applicationContext.xml的spring配置信息 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xmlns:tx=&quot;http://www.alibaba.com/schema/stat&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.alibaba.com/schema/stat http://www.alibaba.com/schema/stat.xsd&quot;&gt; &lt;!--配置属性文件的加载--&gt; &lt;context:property-placeholder location=&quot;classpath:database.properties&quot;&gt;&lt;/context:property-placeholder&gt; &lt;!--配置数据源--&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;${jdbc.driver}&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;${jdbc.url}&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;${jdbc.username}&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot;/&gt; &lt;/bean&gt; &lt;!--配置sqlsessionFactory--&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis/mybatis-config.xml&quot;/&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mybatis/mapper/*.xml&quot;/&gt; &lt;/bean&gt; &lt;!--配置mapper扫描注解--&gt; &lt;bean id=&quot;scannerConfigurer&quot; class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.sugarzhang.spring.mapper&quot;/&gt; &lt;/bean&gt; &lt;!--配置事务管理器--&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt; &lt;!--配置注解扫描的包--&gt; &lt;context:component-scan base-package=&quot;com.sugarzhang.spring&quot; use-default-filters=&quot;true&quot;&gt; &lt;!--排除Controller--&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt; &lt;/context:component-scan&gt; &lt;!--配置事务注解--&gt; &lt;tx:annotation-driven/&gt; &lt;!--配置aop--&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;/beans&gt; 5.配置springmvc-servlet.xml的springMVC的配置信息 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!--配置视图解析器--&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/views/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt; &lt;/bean&gt; &lt;!--配置资源过滤器--&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!--配置mvc扫描的包--&gt; &lt;context:component-scan base-package=&quot;com.sugarzhang.spring&quot; use-default-filters=&quot;false&quot;&gt; &lt;!--只扫描controller--&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt; &lt;/context:component-scan&gt; &lt;!--配置MVC的注解扫描驱动--&gt; &lt;mvc:annotation-driven/&gt; &lt;/beans&gt; 6.配置web.xml的配置信息 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;!--配置springIOC--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--配置springMVC控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/springmvc-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--配置springMVC编码--&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;/web-app&gt; ","link":"https://ziznah.github.io/post/3/"},{"title":"在虚拟机 VMware 下安装 Linux","content":" Java后续学习中使用Linux系统，首先要将Linux的安装精通。 安装Linux的工具，以及Linux版本 VMware Woekstation (WORKSTATION 12 PRO) Linux：Centos Centos：CentOS-6.7-i386-bin-DVD1.iso 注意：这里Centos使用的是 32位，大家可以按需选择 Centos 的版本。 在VMware创建虚拟机 1.创建一个新的虚拟机 2.Centos镜像选择 3.Centos操作系统安装版本 4.选择Linux命名以及安装位置 这里安装位置是否加虚拟机名称可有可无 5.设置虚拟机的Linux大小 6.自定义硬件 内容、处理器可以自己设置，这里ISO映像选择CentOS-6.7-i386-bin-DVD1.iso 到此，Linux在虚拟机上的配置全部完成，下面开始Linux系统的安装。 安装Linux 1.在VMware上开启虚拟机 2.安装选项 默认选择第一项即可 跳过检测 这里会出现磁盘检测，这里使用Tab切换到Skip，敲Enter跳过即可，这里也可以选择OK，不过检测会耗费大量时间。 3.进入安装GUI界面 选择语言 这里推荐默认 English，可以自行选择 选择键盘布局 选择存储格式 这里选择Basic Storage Devices即可 格式化磁盘 设置主机名 选择时区 设置ROOT密码 这里密码简单会跳出提示，这里选择Use Anyway即可 初始化设置 选择Use All Space ​ 选择Write changes to disk 选择Centos的版本，这里选择Desktop 选择Desktop会默认安装一些软件，选择其他样式可能会缺少一些软件，后期也可以自己安装。 等待安装 重新引导 安装成功之后，我们需要重新引导一下，稍等片刻即可进入Centos，Please enjoy~ 后续 欢迎界面 同意许可 设置用户 设置时间 设置Kdump，默认即可。 ","link":"https://ziznah.github.io/post/2/"},{"title":"Linux下安装Java配置环境","content":"JDK的安装 准备工作：安装依赖的环境 yum -y install glibc.i686 yum -y install libaio.so.1 libgcc_s.so.1 libstdc++.so.6 yum -y install gcc-c++ yum -y install libaio* 检查之前是否安装JDK ，安装过则卸载 rpm -qa | grep -i jdk 参数-i忽略大小写 ​如果查询结果为空，则当前Linux未安装虚拟机 如果查询有结果，则执行下面命令，进行卸载jdk rpm -e --nodeps 程序名称 安装JDK 创建JDK的安装路径 mkdir /usr/local/java 上传JDK安装包 解压 tar -zxvf 安装包 -C 指定目录 配置环境变量(在Linux下 使用:来分隔) vim /etc/profile 在末尾添加如下消息 export JAVA_HOME=/usr/local/jdk/jdk1.8.0_241 export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$JAVA_HOME/bin:$PATH 重新加载环境变量配置文件 ~~~shell source /etc/profile ~~~ 测试是否配置成功 ~~~shell java -version ~~~ Tomcat的安装 检查之前是否安装tomcat，安装过则卸载 rpm -qa | grep -i tomcat 如果查询结果为空，则当前Linux未安装虚拟机 如果查询有结果，则执行下面命令，进行卸载tomcat rpm -e --nodeps tomcat 上传tomcat的安装文件 将tomcat的压缩包上传到根目录下 创建tomcat的安装路径(一般软件安装在usr下的local里面) mkdir /usr/local/tomcat 解压tomcat tar -zxvf apache-tomcat-8.5.51.tar.gz -C /usr/local/tomcat 配置环境变量 vim /etc/profile 添加CATALINA和PATH路径 export CATALINA_HOME=/usr/local/tomcat/apache-tomcat-8.5.51 export PATH=CATALINAHOME/bin:CATALINA_HOME/bin:CATALINAH​OME/bin:PATH 重新加载环境变量配置文件 source /etc/profile 启动tomcat 进入tomcat安装路径的bin目录下 cd /usr/local/tomcat/apache-tomcat-8.5.51/bin 执行启动命令 ./startup.sh 本机远程访问测试是否启动成功 将tomcat服务加入开机启动项。 首先将tomcat安装目录下bin目录中的startup.sh文件链接到/etc/init.d/下并起名为tomcat(etc目录下的init.d实际目录是etc/rc.d/init.d) ln -s /usr/local/tomcat/apache-tomcat-8.5.51/bin/startup.sh /etc/init.d/tomcat 如果权限不够，则使用以下代码赋予最高权限 chmod 777 tomcat 通过chkconfig命令将tomcat服务加入到自启动服务项中。(在任何目录下都可以执行以下命令) chkconfig --add tomcat 注意：服务名称tomcat就是我们将startup.sh链接到/etc/init.d/时重命名的名称。 如果出现以下代码 service tomcat does not support chkconfig 那么重新打开tomcat文件配置权限信息 vim /etc/init.d/tomcat 在头部#！/bin/sh下添加 #chkconfig:2345 10 90 在下方添加JDK以及tomcat的环境变量 export JAVA_HOME=/usr/local/jdk/jdk1.8.0_241 export CATALINA_HOME=/usr/local/tomcat/apache-tomcat-8.5.51 查看是否添加成功 chkconfig --list tomcat 如果2，3，4，5显示为on 则添加成功，若失败，则重新执行一次。 Mysql的安装 检查之前是否安装mysql，安装过则卸载 rpm -qa | grep -i mysql 如果已经安装了库文件，应该先卸载，不然会出现覆盖错误。注意卸载时使用了--nodeps选项，忽略了依赖关系 rpm -e --nodeps 程序名称 上传mysql的安装文件 创建mysql的安装路径 mkdir /usr/local/mysql 解压mysql 添加mysql用户组和mysql用户，用于设置mysql安装目录文件所有者和所属组。 groupadd mysql useradd -r -g mysql mysql 进入mysql解压目录，并更改所属的组和用户。 cd /usr/local/mysql/mysql-5.6.31-linux-glibc2.5-x86_64 chown -R mysql . chgrp -R mysql . 注意：不要忘记mysql后的 '.'，代表所有目录。 执行mysql_install_db脚本，对mysql中的data目录进行初始化并创建一些系统表格。注意mysql服务进程mysqld运行时会访问data目录，所以必须由启动mysqld进程的用户(就是我们之前设置的mysql用户)执行这个脚本，或者用root执行，但是加上参数--user=mysql。 scripts/mysql_install_db --user=mysql 注意：如果出现以下错误 FATAL ERROR: please install the following Perl modules before executing scripts/mysql_install_db: Data::Dumper 则需要先安装安装autoconf库 yum -y install autoconf 将mysql/目录下除了data/目录的所有文件，改回root用户所有，mysql用户只需作为mysql/data/目录下所有文件的所有者。 chown -R root . chown -R mysql data 注意：同样，别忘记root后面的'.' 复制配置文件到etc目录下 my-default.cnf文件在support-files目录下 cp my-default.cnf /etc/my.cnf 并查看my.cnf配置，修改basedir cd /etc/ vim my.cnf 找到basedir修改为如下内容 basedir =/usr/local/mysql/mysql-5.6.31-linux-glibc2.5-x86_64 将mysqld服务加入开机启动项。 首先需要将support-files目录下的mysql.server服务脚本复制到/etc/init.d/，并重命名为mysqld。 cp mysql.server /etc/init.d/mysqld 通过chkconfig命令将mysqld服务加入到自启动服务项中。(在任何目录下都可以执行以下命令) chkconfig --add mysqld 注意：服务名称mysqld就是我们将mysql.server复制到/etc/init.d/时重命名的名称。 查看是否添加成功 chkconfig --list mysqld 如果2，3，4，5显示为on 则添加成功，若失败，则重新执行一次。 启动mysql service mysqld start 如果出现SUCCESS 则代表启动成功 如果出现以下错误error ERROR! The server quit without updating PID file (/usr/local/mysql/mysql-5.6.31-linux-glibc2.5-x86_64/data/quality-unicorns-2.localdomain.pid). 则使用以下代码将data文件夹重新赋予权限，然后重新启动mysql chown -R mysql.mysql /usr/local/mysql/mysql-5.6.31-linux-glibc2.5-x86_64/data service mysqld start 运行客户端程序mysql查看是否连接到mysqld 进入mysql的安装目录下的bin目录中，执行以下代码即可登录mysql ./mysql 或 /usr/local/mysql/mysql-5.6.31-linux-glibc2.5-x86_64/bin/mysql 设置mysql初始密码并登录 如果刚安装号mysql，超级用户root是没有密码，所以直接回车即可进入到mysql中 修改密码 定位到你的mysql安装目录bin目录下执行以下代码将密码设置为123456 ./mysqladmin -u root password 123456 再次登录mysql，则需要输入完整的登录才能成功登录 ./mysql -u root -p 回车再输入上面设置的密码即可 为了避免每次都输入mysql的全路径，添加mysql的环境变量 打开系统环境变量配置文件 vim /etc/profile 添加下面两行命令 export MYSQL_HOME=/usr/local/mysql/mysql-5.6.31-linux-glibc2.5-x86_64 export PATH=$PATH:$MYSQL_HOME/bin 重新加载环境变量文件 source /etc/profile ################ vim的安装 yum -y install vim* Linux常用命令 cp 复制文件(如果复制目录文件需要加上-r) rm 删除文件(如果删除目录文件需要加上-r，如果强制删除需要加上-f) vi/vim 编辑文件(文件编辑器):命令模式-&gt;编辑模式-&gt;底行模式 clear 清屏 cat 查看文件 tar 压缩文件或解压文件(-zxvf) tail(如果你想查看文件的后10行，可以使用tail命令，如：tail -10 /etc/passwd 或 tail -n 10 /etc/passwd tail -f /var/log/messages 参数-f使tail不停的去读最新的内容，这样有实时监视的效果 用Ctrl+c来终止！)：当文件较大时使用，查看文件的后几行。 reboot 重启虚拟机 halt 关机 ifconfig 查看本机ip地址 ps -ef 查看进程号 ps -aux ","link":"https://ziznah.github.io/post/1/"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 Windows，MacOS 或 Linux 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前 🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"https://ziznah.github.io/post/hello-gridea/"}]}